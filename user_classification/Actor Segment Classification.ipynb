{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fnmatch\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.decomposition import PCA, RandomizedPCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initializing input dataframe: \n",
      "(20245, 13)\n",
      "==> Concatenating dataframe from actor_classification_train_copy.csv: \n",
      "(20245, 13)\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'data/manually_categorized/'\n",
    "input_prefix = 'actor_classification_train'\n",
    "train = None\n",
    "for file in os.listdir(input_dir):\n",
    "  if fnmatch.fnmatch(file, input_prefix+'*.csv'):\n",
    "    if train is None:\n",
    "      print \"==> Initializing input dataframe: \"\n",
    "      train = pd.read_csv(open(input_dir+file,'rU'),\n",
    "                          engine='python', sep=\",\", quoting=1)\n",
    "    else:\n",
    "      print \"==> Concatenating dataframe from \" + file + \": \"\n",
    "      train = pd.concat([train, pd.read_csv(open(input_dir+file,'rU'),\n",
    "                          engine='python', sep=\",\", quoting=1)])\n",
    "    train.drop_duplicates(inplace=True)\n",
    "    print train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>summary</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>link</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>segment</th>\n",
       "      <th>manual_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guy</td>\n",
       "      <td>ZZ0</td>\n",
       "      <td>en</td>\n",
       "      <td>394</td>\n",
       "      <td>14626</td>\n",
       "      <td>122072</td>\n",
       "      <td>Martial arts, contortion, 7-string elec violin...</td>\n",
       "      <td>122030</td>\n",
       "      <td>http://www.twitter.com/ZZ0</td>\n",
       "      <td>745</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>party here</td>\n",
       "      <td>zxynisgod</td>\n",
       "      <td>es</td>\n",
       "      <td>75357</td>\n",
       "      <td>169818</td>\n",
       "      <td>44087</td>\n",
       "      <td>���I hate One Direction.�� -people who have lo...</td>\n",
       "      <td>72756</td>\n",
       "      <td>http://www.twitter.com/zxynisgod</td>\n",
       "      <td>327</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>?��</td>\n",
       "      <td>Zxntio</td>\n",
       "      <td>en</td>\n",
       "      <td>24372</td>\n",
       "      <td>38662</td>\n",
       "      <td>118</td>\n",
       "      <td>@rantzantio</td>\n",
       "      <td>119602</td>\n",
       "      <td>http://www.twitter.com/Zxntio</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>business</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>�_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_</td>\n",
       "      <td>zxkia</td>\n",
       "      <td>en-gb</td>\n",
       "      <td>9874</td>\n",
       "      <td>119158</td>\n",
       "      <td>127928</td>\n",
       "      <td>Don't take me seriously. || Turn off rts &amp; tur...</td>\n",
       "      <td>197890</td>\n",
       "      <td>http://www.twitter.com/zxkia</td>\n",
       "      <td>170</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zxkia</td>\n",
       "      <td>en</td>\n",
       "      <td>94</td>\n",
       "      <td>5514</td>\n",
       "      <td>12563</td>\n",
       "      <td>Somewhere between I want it and I got it. ~ Pr...</td>\n",
       "      <td>24316</td>\n",
       "      <td>http://twitter.com/Zxkia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name screen_name   lang  \\\n",
       "0                                       Guy         ZZ0     en   \n",
       "1                               party here    zxynisgod     es   \n",
       "2                                       ?��      Zxntio     en   \n",
       "3  �_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_       zxkia  en-gb   \n",
       "4                                       NaN       Zxkia     en   \n",
       "\n",
       "   favourites_count  statuses_count  friends_count  \\\n",
       "0               394           14626         122072   \n",
       "1             75357          169818          44087   \n",
       "2             24372           38662            118   \n",
       "3              9874          119158         127928   \n",
       "4                94            5514          12563   \n",
       "\n",
       "                                             summary  followers_count  \\\n",
       "0  Martial arts, contortion, 7-string elec violin...           122030   \n",
       "1  ���I hate One Direction.�� -people who have lo...            72756   \n",
       "2                                        @rantzantio           119602   \n",
       "3  Don't take me seriously. || Turn off rts & tur...           197890   \n",
       "4  Somewhere between I want it and I got it. ~ Pr...            24316   \n",
       "\n",
       "                               link  listed_count verified   segment  \\\n",
       "0        http://www.twitter.com/ZZ0           745    False    person   \n",
       "1  http://www.twitter.com/zxynisgod           327    False    person   \n",
       "2     http://www.twitter.com/Zxntio             5    False  business   \n",
       "3      http://www.twitter.com/zxkia           170    False    person   \n",
       "4          http://twitter.com/Zxkia           NaN      NaN       NaN   \n",
       "\n",
       "   manual_segment  \n",
       "0               0  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>summary</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>link</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>segment</th>\n",
       "      <th>manual_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20246</th>\n",
       "      <td>DOSE</td>\n",
       "      <td>___Dose___</td>\n",
       "      <td>en</td>\n",
       "      <td>8</td>\n",
       "      <td>20194</td>\n",
       "      <td>12</td>\n",
       "      <td>A Strong Dose of Amazing People, Places, and T...</td>\n",
       "      <td>421003</td>\n",
       "      <td>http://www.twitter.com/___Dose___</td>\n",
       "      <td>2949</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20247</th>\n",
       "      <td>One Direction News</td>\n",
       "      <td>_______1d_4ever</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>18578</td>\n",
       "      <td>37552</td>\n",
       "      <td>All the latest One Direction news from around ...</td>\n",
       "      <td>46205</td>\n",
       "      <td>http://www.twitter.com/_______1d_4ever</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20248</th>\n",
       "      <td>Tyrne Clark</td>\n",
       "      <td>10223335</td>\n",
       "      <td>en</td>\n",
       "      <td>467</td>\n",
       "      <td>13481</td>\n",
       "      <td>60692</td>\n",
       "      <td>Shouldn't a strange and wonderful world be ful...</td>\n",
       "      <td>58620</td>\n",
       "      <td>http://www.twitter.com/10223335</td>\n",
       "      <td>54</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20249</th>\n",
       "      <td>1776</td>\n",
       "      <td>1776</td>\n",
       "      <td>en</td>\n",
       "      <td>6586</td>\n",
       "      <td>9746</td>\n",
       "      <td>1293</td>\n",
       "      <td>Global incubator &amp; seed fund helping startups ...</td>\n",
       "      <td>87459</td>\n",
       "      <td>http://www.twitter.com/1776</td>\n",
       "      <td>1125</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20250</th>\n",
       "      <td>350 dot org</td>\n",
       "      <td>350</td>\n",
       "      <td>en</td>\n",
       "      <td>1153</td>\n",
       "      <td>25876</td>\n",
       "      <td>19502</td>\n",
       "      <td>Join a global movement that's inspiring the wo...</td>\n",
       "      <td>266424</td>\n",
       "      <td>http://www.twitter.com/350</td>\n",
       "      <td>5870</td>\n",
       "      <td>True</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name      screen_name lang  favourites_count  \\\n",
       "20246                DOSE       ___Dose___   en                 8   \n",
       "20247  One Direction News  _______1d_4ever   en                 0   \n",
       "20248         Tyrne Clark         10223335   en               467   \n",
       "20249                1776             1776   en              6586   \n",
       "20250         350 dot org              350   en              1153   \n",
       "\n",
       "       statuses_count  friends_count  \\\n",
       "20246           20194             12   \n",
       "20247           18578          37552   \n",
       "20248           13481          60692   \n",
       "20249            9746           1293   \n",
       "20250           25876          19502   \n",
       "\n",
       "                                                 summary  followers_count  \\\n",
       "20246  A Strong Dose of Amazing People, Places, and T...           421003   \n",
       "20247  All the latest One Direction news from around ...            46205   \n",
       "20248  Shouldn't a strange and wonderful world be ful...            58620   \n",
       "20249  Global incubator & seed fund helping startups ...            87459   \n",
       "20250  Join a global movement that's inspiring the wo...           266424   \n",
       "\n",
       "                                         link  listed_count verified segment  \\\n",
       "20246       http://www.twitter.com/___Dose___          2949    False  person   \n",
       "20247  http://www.twitter.com/_______1d_4ever            46    False  person   \n",
       "20248         http://www.twitter.com/10223335            54    False  person   \n",
       "20249             http://www.twitter.com/1776          1125    False  person   \n",
       "20250              http://www.twitter.com/350          5870     True  person   \n",
       "\n",
       "       manual_segment  \n",
       "20246               0  \n",
       "20247               0  \n",
       "20248               1  \n",
       "20249               0  \n",
       "20250               0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformer with LabelEncoder for 'verified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VerifiedTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X.verified.fillna(False, inplace=True)\n",
    "        X.verified = LabelEncoder().fit_transform(X.verified)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    16913\n",
      "True      2908\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "verified_transformer = VerifiedTransformer()\n",
    "verified_transformer.transform(train)\n",
    "\n",
    "print train.verified.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom OneHotEncoding for lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LangOneHotEncoding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        valid_langs = list(set(X.lang) - set([None, np.nan, 'Select Language...']))\n",
    "        self.feature_names_ = [\"lang_\"+str(l) for l in valid_langs if type(l) == str]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        check_is_fitted(self, 'feature_names_')\n",
    "        \n",
    "        X = X.copy()\n",
    "        X[\"lang\"].fillna(\"\", inplace=True)\n",
    "        for lang_feature in self.feature_names_:\n",
    "            X[lang_feature] = [(1 if lang_feature == \"lang_\"+v else 0) for v in X[\"lang\"].values]\n",
    "        \n",
    "        X.drop([\"lang\"], axis=1, inplace=True)\n",
    "        return X\n",
    "    \n",
    "lang_ohe = LangOneHotEncoding().fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing NAs on textual fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FillTextNA(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols, replace_by=\"\"):\n",
    "        self.cols = cols\n",
    "        self.replace_by = replace_by\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[c].fillna(self.replace_by, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameTfidfVectorizer for textual fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataFrameTfidfVectorizer(TfidfVectorizer):\n",
    "\n",
    "    def __init__(self, col, prefix=None, input='content', encoding='utf-8',\n",
    "                 decode_error='strict', strip_accents=None, lowercase=True,\n",
    "                 preprocessor=None, tokenizer=None, analyzer='word',\n",
    "                 stop_words=None, token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "                 ngram_range=(1, 1), max_df=1.0, min_df=1,\n",
    "                 max_features=None, vocabulary=None, binary=False,\n",
    "                 dtype=np.int64, norm='l2', use_idf=True, smooth_idf=True,\n",
    "                 sublinear_tf=False):\n",
    "        super(DataFrameTfidfVectorizer, self).__init__(\n",
    "            input=input, encoding=encoding, decode_error=decode_error,\n",
    "            strip_accents=strip_accents, lowercase=lowercase,\n",
    "            preprocessor=preprocessor, tokenizer=tokenizer, analyzer=analyzer,\n",
    "            stop_words=stop_words, token_pattern=token_pattern,\n",
    "            ngram_range=ngram_range, max_df=max_df, min_df=min_df,\n",
    "            max_features=max_features, vocabulary=vocabulary, binary=binary,\n",
    "            dtype=dtype)\n",
    "\n",
    "        self.col = col\n",
    "        self.prefix = prefix or col\n",
    "        \n",
    "    def treat_special_char(self, c):\n",
    "        try:\n",
    "            encoding = chardet.detect(str(c))['encoding'] or \"KOI8-R\"\n",
    "            return '0' if c.isdigit() else c.decode(encoding)\n",
    "        except:        \n",
    "            return '9'\n",
    "\n",
    "    def treat_special_chars(self, col):\n",
    "        col.fillna(\"null\", inplace=True)\n",
    "        col = [''.join([self.treat_special_char(c) for c in list(n)]) \n",
    "               for n in col.values]\n",
    "        return col\n",
    "\n",
    "    def fit(self, dataframe, y=None):\n",
    "        dataframe = dataframe.copy()\n",
    "        dataframe[self.col] = self.treat_special_chars(dataframe[self.col])\n",
    "        super(DataFrameTfidfVectorizer, self).fit(dataframe[self.col])\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, dataframe, y=None):\n",
    "        dataframe = dataframe.copy()\n",
    "        dataframe[self.col] = self.treat_special_chars(dataframe[self.col])\n",
    "        field_matrix = super(DataFrameTfidfVectorizer, self).fit_transform(dataframe[self.col])\n",
    "        features_names = map(lambda f: \"_\".join([self.prefix,f]), super(DataFrameTfidfVectorizer, self).get_feature_names())\n",
    "        field_df = pd.DataFrame(field_matrix.A, columns=features_names)\n",
    "\n",
    "        dataframe = dataframe.join(field_df)\n",
    "\n",
    "        return dataframe\n",
    "\n",
    "    def transform(self, dataframe, copy=True):\n",
    "        dataframe = dataframe.copy()\n",
    "        dataframe[self.col] = self.treat_special_chars(dataframe[self.col])\n",
    "        field_matrix = super(DataFrameTfidfVectorizer, self).transform(dataframe[self.col])\n",
    "        features_names = map(lambda f: \"_\".join([self.prefix,f]), super(DataFrameTfidfVectorizer, self).get_feature_names())\n",
    "        field_df = pd.DataFrame(field_matrix.A, columns=features_names)\n",
    "\n",
    "        dataframe = dataframe.join(field_df)\n",
    "\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_chars_tfidf = DataFrameTfidfVectorizer(col=\"name\", \n",
    "                                            prefix=\"name_c\",\n",
    "                                            ngram_range=(3, 5), \n",
    "                                            analyzer=\"char\",\n",
    "                                            binary=True, #False\n",
    "                                            min_df = 50) #8\n",
    "\n",
    "name_words_tfidf = DataFrameTfidfVectorizer(col=\"name\", \n",
    "                                            prefix=\"name_w\", \n",
    "                                            token_pattern=r'\\w+',\n",
    "                                            ngram_range=(1, 2), \n",
    "                                            analyzer=\"word\",\n",
    "                                            binary=True, #False\n",
    "                                            min_df = 10) #8\n",
    "\n",
    "screen_name_tfidf = DataFrameTfidfVectorizer(col=\"screen_name\", \n",
    "                                             ngram_range=(3, 5), \n",
    "                                             analyzer=\"char\",\n",
    "                                             binary=True, #False\n",
    "                                             min_df = 50) #8\n",
    "\n",
    "summary_tfidf = DataFrameTfidfVectorizer(col=\"summary\",\n",
    "                                         token_pattern=r'\\w+',\n",
    "                                         ngram_range=(1, 3), \n",
    "                                         analyzer=\"word\",\n",
    "                                         binary=True, #False\n",
    "                                         sublinear_tf=True, \n",
    "                                         stop_words='english',\n",
    "                                         min_df = 50) #5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further textual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextToLowerCase(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[c] = [t.lower() for t in X[c].values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NumberOfWords(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[\"number_of_words_in_\"+c] = [len(t.split(' ')) for t in X[c].values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NumberNonAlphaNumChars(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[\"number_of_non_alphanum_in_\"+c] = [len(re.sub(r\"[\\w\\d]\",\"\", t)) for t in X[c].values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NumberUpperCaseChars(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[\"number_of_upper_case_chars_in_\"+c] = [len(re.sub(r\"[^A-Z]\",\"\", t)) for t in X[c].values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NumberCamelCaseWords(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[\"number_of_camel_case_words_in_\"+c] = [len(re.findall(r\"^[A-Z][a-z]|\\s[A-Z][a-z]\", t)) \n",
    "                                                         for t in X[c].values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NumberOfMentions(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[\"number_of_mentions_in_\"+c] = [len(re.findall(r\"\\s@[a-zA-Z]\",t)) \n",
    "                                                         for t in X[c].values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NumberOfPeriods(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[\"number_of_periods_in_\"+c] = [len(t.split(\". \")) \n",
    "                                                         for t in X[c].values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AvgWordsPerPeriod(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[\"avg_words_per_period_in_\"+c] = [np.mean([len(p.split(\" \")) for p in t.split(\". \")]) \n",
    "                                                         for t in X[c].values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MentionToFamilyRelation(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def count_mentions(self, t):\n",
    "        count = 0\n",
    "        tokenizer = nltk.RegexpTokenizer(r'[a-z]+')\n",
    "        for tkn in tokenizer.tokenize(t):\n",
    "              if tkn in [\"husband\",\"wife\",\"father\",\"mother\",\"daddy\",\"mommy\",\n",
    "                         \"grandfather\",\"grandmother\",\"grandpa\",\"grandma\"]:\n",
    "                    count += 1\n",
    "        return count\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[\"mention_to_family_relation_in_\"+c] = [self.count_mentions(t) \n",
    "                                                         for t in X[c].values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professional Occupations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mentions to US occupations according to http://data.okfn.org/data/johnlsheridan/occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accountant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accounts assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accounts clerk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accounts manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accounts staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Occupations\n",
       "0          accountant\n",
       "1  accounts assistant\n",
       "2      accounts clerk\n",
       "3    accounts manager\n",
       "4      accounts staff"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupations = pd.read_csv(\"https://raw.githubusercontent.com/johnlsheridan/occupations/master/occupations.csv\")\n",
    "occupations.Occupations = [o.lower() for o in occupations.Occupations.values]\n",
    "occupations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MentionToOccupation(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        occupations = pd.read_csv(\"https://raw.githubusercontent.com/johnlsheridan/occupations/master/occupations.csv\")\n",
    "        self.occupations_ = [o.lower() for o in occupations.Occupations.values]\n",
    "        return self\n",
    "    \n",
    "    def count_mentions(self, t):\n",
    "        count = 0\n",
    "        for o in self.occupations_:\n",
    "            count += len(re.findall(r\"(^|\\W)%s(\\W|$)\" % o, t))\n",
    "            if count == 3:\n",
    "                break\n",
    "        return count\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        check_is_fitted(self, 'occupations_')\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[\"mention_to_occupation_in_\"+c] = [self.count_mentions(t) \n",
    "                                                     for t in X[c].values]\n",
    "        return X\n",
    "    \n",
    "mention_to_occupation = MentionToOccupation([\"summary\"]).fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Person Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Person names according to http://deron.meranda.us/data/census-dist-female-first.txt and http://deron.meranda.us/data/census-dist-male-first.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_names = pd.read_csv(\"http://deron.meranda.us/data/census-dist-female-first.txt\", names=[\"name\"])\n",
    "male_names   = pd.read_csv(\"http://deron.meranda.us/data/census-dist-male-first.txt\", names=[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARY           2.629  2.629      1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PATRICIA       1.073  3.702      2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LINDA          1.035  4.736      3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BARBARA        0.980  5.716      4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELIZABETH      0.937  6.653      5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name\n",
       "0  MARY           2.629  2.629      1\n",
       "1  PATRICIA       1.073  3.702      2\n",
       "2  LINDA          1.035  4.736      3\n",
       "3  BARBARA        0.980  5.716      4\n",
       "4  ELIZABETH      0.937  6.653      5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JAMES          3.318  3.318      1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOHN           3.271  6.589      2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROBERT         3.143  9.732      3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MICHAEL        2.629 12.361      4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WILLIAM        2.451 14.812      5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name\n",
       "0  JAMES          3.318  3.318      1\n",
       "1  JOHN           3.271  6.589      2\n",
       "2  ROBERT         3.143  9.732      3\n",
       "3  MICHAEL        2.629 12.361      4\n",
       "4  WILLIAM        2.451 14.812      5"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4275\n",
      "1219\n",
      "5163\n"
     ]
    }
   ],
   "source": [
    "female_names = [re.sub(r\"[^a-z]\",\"\",n.lower()) for n in female_names.name.values]\n",
    "male_names   = [re.sub(r\"[^a-z]\",\"\",n.lower()) for n in male_names.name.values]\n",
    "person_names = list(set(male_names + female_names))\n",
    "print len(female_names)\n",
    "print len(male_names)\n",
    "print len(person_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PersonNames(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        female_names = pd.read_csv(\"http://deron.meranda.us/data/census-dist-female-first.txt\", names=[\"name\"])\n",
    "        male_names   = pd.read_csv(\"http://deron.meranda.us/data/census-dist-male-first.txt\", names=[\"name\"])\n",
    "        female_names = [re.sub(r\"[^a-z]\",\"\",n.lower()) for n in female_names.name.values]\n",
    "        male_names   = [re.sub(r\"[^a-z]\",\"\",n.lower()) for n in male_names.name.values]        \n",
    "        self.person_names_ = list(set(male_names + female_names))\n",
    "        return self\n",
    "    \n",
    "    def count_mentions(self, t):\n",
    "        count = 0\n",
    "        tokenizer = nltk.RegexpTokenizer(r'[a-z]+')\n",
    "        for name in tokenizer.tokenize(t):\n",
    "            if name in self.person_names_:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        check_is_fitted(self, 'person_names_')\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X[\"person_names_in_\"+c] = [self.count_mentions(t) \n",
    "                                            for t in X[c].values]\n",
    "        return X\n",
    "    \n",
    "person_names = PersonNames([\"name\"]).fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Columns Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DropColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X.drop([c], axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Imputer and np array transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NumpyArrayTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X = X.reindex_axis(sorted(X.columns), axis=1)\n",
    "        X.fillna(0, inplace=True)\n",
    "        return np.asarray(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Debugger for pipeline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Debugger(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print \"-------------------------\"\n",
    "        print self.name\n",
    "        print \"Dataset dimensions:\"\n",
    "        print X.shape\n",
    "        print \"-------------------------\"\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome = \"manual_segment\"\n",
    "\n",
    "features = list(set(train.columns) - set([outcome]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RandomForestClassifier - 0.69\n",
    "# LogisticRegression - 0.57\n",
    "# GaussianNB 0.45\n",
    "# LinearSVC 0.5\n",
    "# KNeighborsClassifier 0.58\n",
    "\n",
    "n_estimators = 100\n",
    "\n",
    "# Model Pipeline\n",
    "pipeline = Pipeline([ (\"drop_cols\", DropColumnsTransformer([\"segment\",\"link\"])),\n",
    "                      (\"verified\", VerifiedTransformer()),\n",
    "                      (\"lang\", lang_ohe),\n",
    "                      (\"fill_text_na\", FillTextNA([\"screen_name\",\"name\",\"summary\"], \"null\")),\n",
    "                      (\"qt_words\", NumberOfWords([\"name\",\"summary\"])),\n",
    "                      (\"qt_non_alphanum_chars\", NumberNonAlphaNumChars([\"name\",\"summary\"])),\n",
    "                      (\"qt_upper_case_chars\", NumberUpperCaseChars([\"name\",\"summary\"])),\n",
    "                      (\"qt_camel_case_words\", NumberCamelCaseWords([\"name\",\"summary\"])),\n",
    "                      (\"qt_mentions\", NumberOfMentions([\"summary\"])),\n",
    "                      (\"qt_periods\", NumberOfPeriods([\"summary\"])),\n",
    "                      (\"avg_words_per_period\", AvgWordsPerPeriod([\"summary\"])),\n",
    "                      (\"lower_case\", TextToLowerCase([\"screen_name\",\"name\",\"summary\"])),\n",
    "                      (\"family\", MentionToFamilyRelation([\"summary\"])),\n",
    "                      (\"person_names\", person_names),\n",
    "                      (\"occupations\", mention_to_occupation),\n",
    "                      (\"name_chars_tfidf\", name_chars_tfidf),\n",
    "                      (\"name_words_tfidf\", name_words_tfidf),\n",
    "                      (\"screen_name_tfidf\", screen_name_tfidf),\n",
    "                      (\"summary_tfidf\", summary_tfidf),\n",
    "                      (\"drop_text_cols\", DropColumnsTransformer([\"screen_name\",\"name\",\"summary\"])),\n",
    "                      (\"debugger\", Debugger(\"Dataset Details\")),\n",
    "                      (\"nparray\", NumpyArrayTransformer()),\n",
    "                      (\"model\", RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1784  608]\n",
      " [ 765 1905]]\n",
      "#### SCORE:0.72876333465\n",
      "[[1792  567]\n",
      " [ 860 1842]]\n",
      "#### SCORE:0.718039913061\n",
      "[[1773  579]\n",
      " [ 737 1972]]\n",
      "#### SCORE:0.739972337483\n",
      "[[1786  562]\n",
      " [ 820 1893]]\n",
      "#### SCORE:0.726931436475\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(n=len(train), n_folds=4, shuffle=True)\n",
    "b_scores, svc_scores = [], []\n",
    "\n",
    "for tr_indices, cv_indices in k_fold:\n",
    "    tr    = train.iloc[tr_indices,:].loc[:, features].copy()\n",
    "    cv    = train.iloc[cv_indices,:].loc[:, features].copy()\n",
    "\n",
    "    tr_y  = train.iloc[tr_indices,:][outcome].values\n",
    "    cv_y  = train.iloc[cv_indices,:][outcome].values\n",
    "\n",
    "    pipeline.fit(tr, tr_y)\n",
    "\n",
    "    print(confusion_matrix(cv_y, pipeline.predict(cv)))    \n",
    "    print('#### SCORE:' + str(pipeline.score(cv, cv_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('drop_cols', DropColumnsTransformer(cols=['segment', 'link'])), ('verified', VerifiedTransformer()), ('lang', LangOneHotEncoding()), ('fill_text_na', FillTextNA(cols=['screen_name', 'name', 'summary'], replace_by='null')), ('qt_words', NumberOfWords(cols=['name', 'summary'])), ('qt_non_alpha...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.set_params(model__n_estimators = n_estimators)\n",
    "pipeline.fit(train.loc[:,features], train.loc[:,outcome])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/manually_categorized/actor_classification_trained_model_20151129.pkl']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"data/manually_categorized/actor_classification_trained_model_20151129.pkl\"\n",
    "joblib.dump(pipeline, model_path, compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = ['{\"name\":\"Светлана Петухова\",\"screen_name\":\"svpetuhova26623\",\"summary\":\"\",\"lang\":\"ru\",\"favourites_count\":23,\"statuses_count\":14,\"friends_count\":2,\"followers_count\":1,\"listed_count\":1,\"verified\":0}',\n",
    "             '{\"lang\":\"en\",\"summary\":\"Artist, Writer, Designer. Tweets on tech, culture, art, animals, love the socioeconomy.\",\"verified\":0,\"followers_count\":175,\"friends_count\":397,\"favourites_count\":228,\"statuses_count\":410,\"listed_count\":12,\"name\":\"Daniel Adornes\",\"screen_name\":\"daniel_adornes\"}',\n",
    "             '{\"lang\":\"en\",\"summary\":\"Entrepreneur, enthusiast of Data Science!\",\"verified\":1,\"followers_count\":175,\"friends_count\":397,\"favourites_count\":228,\"statuses_count\":410,\"listed_count\":12,\"name\":\"Daniel Adornes\",\"screen_name\":\"daniel_adornes\"}',\n",
    "             '{\"lang\":\"en\",\"summary\":\"Bring your cute dog here and we will wash and feed him for you\",\"verified\":1,\"followers_count\":175,\"friends_count\":397,\"favourites_count\":228,\"statuses_count\":410,\"listed_count\":12,\"name\":\"PetShop Molecão\",\"screen_name\":\"petmolecao\"}']\n",
    "test_data = [json.loads(t) for t in test_data]\n",
    "test_data = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ru</td>\n",
       "      <td>1</td>\n",
       "      <td>Светлана Петухова</td>\n",
       "      <td>svpetuhova26623</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>175</td>\n",
       "      <td>397</td>\n",
       "      <td>en</td>\n",
       "      <td>12</td>\n",
       "      <td>Daniel Adornes</td>\n",
       "      <td>daniel_adornes</td>\n",
       "      <td>410</td>\n",
       "      <td>Artist, Writer, Designer. Tweets on tech, cult...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228</td>\n",
       "      <td>175</td>\n",
       "      <td>397</td>\n",
       "      <td>en</td>\n",
       "      <td>12</td>\n",
       "      <td>Daniel Adornes</td>\n",
       "      <td>daniel_adornes</td>\n",
       "      <td>410</td>\n",
       "      <td>Entrepreneur, enthusiast of Data Science!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>228</td>\n",
       "      <td>175</td>\n",
       "      <td>397</td>\n",
       "      <td>en</td>\n",
       "      <td>12</td>\n",
       "      <td>PetShop Molecão</td>\n",
       "      <td>petmolecao</td>\n",
       "      <td>410</td>\n",
       "      <td>Bring your cute dog here and we will wash and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   favourites_count  followers_count  friends_count lang  listed_count  \\\n",
       "0                23                1              2   ru             1   \n",
       "1               228              175            397   en            12   \n",
       "2               228              175            397   en            12   \n",
       "3               228              175            397   en            12   \n",
       "\n",
       "                name      screen_name  statuses_count  \\\n",
       "0  Светлана Петухова  svpetuhova26623              14   \n",
       "1     Daniel Adornes   daniel_adornes             410   \n",
       "2     Daniel Adornes   daniel_adornes             410   \n",
       "3    PetShop Molecão       petmolecao             410   \n",
       "\n",
       "                                             summary  verified  \n",
       "0                                                            0  \n",
       "1  Artist, Writer, Designer. Tweets on tech, cult...         0  \n",
       "2          Entrepreneur, enthusiast of Data Science!         1  \n",
       "3  Bring your cute dog here and we will wash and ...         1  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = test_model.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business  person\n",
       "0      0.48    0.52\n",
       "1      0.18    0.82\n",
       "2      0.20    0.80\n",
       "3      0.62    0.38"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result, columns=[\"business\",\"person\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
