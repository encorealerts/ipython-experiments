{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA, RandomizedPCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initializing input dataframe: \n",
      "(20245, 13)\n",
      "==> Concatenating dataframe from actor_classification_train_copy.csv: \n",
      "(20245, 13)\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'data/manually_categorized/'\n",
    "input_prefix = 'actor_classification_train'\n",
    "train = None\n",
    "for file in os.listdir(input_dir):\n",
    "  if fnmatch.fnmatch(file, input_prefix+'*.csv'):\n",
    "    if train is None:\n",
    "      print \"==> Initializing input dataframe: \"\n",
    "      train = pd.read_csv(open(input_dir+file,'rU'),\n",
    "                          engine='python', sep=\",\", quoting=1)\n",
    "    else:\n",
    "      print \"==> Concatenating dataframe from \" + file + \": \"\n",
    "      train = pd.concat([train, pd.read_csv(open(input_dir+file,'rU'),\n",
    "                          engine='python', sep=\",\", quoting=1)])\n",
    "    train.drop_duplicates(inplace=True)\n",
    "    print train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>summary</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>link</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>segment</th>\n",
       "      <th>manual_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guy</td>\n",
       "      <td>ZZ0</td>\n",
       "      <td>en</td>\n",
       "      <td>394</td>\n",
       "      <td>14626</td>\n",
       "      <td>122072</td>\n",
       "      <td>Martial arts, contortion, 7-string elec violin...</td>\n",
       "      <td>122030</td>\n",
       "      <td>http://www.twitter.com/ZZ0</td>\n",
       "      <td>745</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>party here</td>\n",
       "      <td>zxynisgod</td>\n",
       "      <td>es</td>\n",
       "      <td>75357</td>\n",
       "      <td>169818</td>\n",
       "      <td>44087</td>\n",
       "      <td>���I hate One Direction.�� -people who have lo...</td>\n",
       "      <td>72756</td>\n",
       "      <td>http://www.twitter.com/zxynisgod</td>\n",
       "      <td>327</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>?��</td>\n",
       "      <td>Zxntio</td>\n",
       "      <td>en</td>\n",
       "      <td>24372</td>\n",
       "      <td>38662</td>\n",
       "      <td>118</td>\n",
       "      <td>@rantzantio</td>\n",
       "      <td>119602</td>\n",
       "      <td>http://www.twitter.com/Zxntio</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>business</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>�_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_</td>\n",
       "      <td>zxkia</td>\n",
       "      <td>en-gb</td>\n",
       "      <td>9874</td>\n",
       "      <td>119158</td>\n",
       "      <td>127928</td>\n",
       "      <td>Don't take me seriously. || Turn off rts &amp; tur...</td>\n",
       "      <td>197890</td>\n",
       "      <td>http://www.twitter.com/zxkia</td>\n",
       "      <td>170</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zxkia</td>\n",
       "      <td>en</td>\n",
       "      <td>94</td>\n",
       "      <td>5514</td>\n",
       "      <td>12563</td>\n",
       "      <td>Somewhere between I want it and I got it. ~ Pr...</td>\n",
       "      <td>24316</td>\n",
       "      <td>http://twitter.com/Zxkia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name screen_name   lang  \\\n",
       "0                                       Guy         ZZ0     en   \n",
       "1                               party here    zxynisgod     es   \n",
       "2                                       ?��      Zxntio     en   \n",
       "3  �_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_܃_       zxkia  en-gb   \n",
       "4                                       NaN       Zxkia     en   \n",
       "\n",
       "   favourites_count  statuses_count  friends_count  \\\n",
       "0               394           14626         122072   \n",
       "1             75357          169818          44087   \n",
       "2             24372           38662            118   \n",
       "3              9874          119158         127928   \n",
       "4                94            5514          12563   \n",
       "\n",
       "                                             summary  followers_count  \\\n",
       "0  Martial arts, contortion, 7-string elec violin...           122030   \n",
       "1  ���I hate One Direction.�� -people who have lo...            72756   \n",
       "2                                        @rantzantio           119602   \n",
       "3  Don't take me seriously. || Turn off rts & tur...           197890   \n",
       "4  Somewhere between I want it and I got it. ~ Pr...            24316   \n",
       "\n",
       "                               link  listed_count verified   segment  \\\n",
       "0        http://www.twitter.com/ZZ0           745    False    person   \n",
       "1  http://www.twitter.com/zxynisgod           327    False    person   \n",
       "2     http://www.twitter.com/Zxntio             5    False  business   \n",
       "3      http://www.twitter.com/zxkia           170    False    person   \n",
       "4          http://twitter.com/Zxkia           NaN      NaN       NaN   \n",
       "\n",
       "   manual_segment  \n",
       "0               0  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>summary</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>link</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>segment</th>\n",
       "      <th>manual_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20246</th>\n",
       "      <td>DOSE</td>\n",
       "      <td>___Dose___</td>\n",
       "      <td>en</td>\n",
       "      <td>8</td>\n",
       "      <td>20194</td>\n",
       "      <td>12</td>\n",
       "      <td>A Strong Dose of Amazing People, Places, and T...</td>\n",
       "      <td>421003</td>\n",
       "      <td>http://www.twitter.com/___Dose___</td>\n",
       "      <td>2949</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20247</th>\n",
       "      <td>One Direction News</td>\n",
       "      <td>_______1d_4ever</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>18578</td>\n",
       "      <td>37552</td>\n",
       "      <td>All the latest One Direction news from around ...</td>\n",
       "      <td>46205</td>\n",
       "      <td>http://www.twitter.com/_______1d_4ever</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20248</th>\n",
       "      <td>Tyrne Clark</td>\n",
       "      <td>10223335</td>\n",
       "      <td>en</td>\n",
       "      <td>467</td>\n",
       "      <td>13481</td>\n",
       "      <td>60692</td>\n",
       "      <td>Shouldn't a strange and wonderful world be ful...</td>\n",
       "      <td>58620</td>\n",
       "      <td>http://www.twitter.com/10223335</td>\n",
       "      <td>54</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20249</th>\n",
       "      <td>1776</td>\n",
       "      <td>1776</td>\n",
       "      <td>en</td>\n",
       "      <td>6586</td>\n",
       "      <td>9746</td>\n",
       "      <td>1293</td>\n",
       "      <td>Global incubator &amp; seed fund helping startups ...</td>\n",
       "      <td>87459</td>\n",
       "      <td>http://www.twitter.com/1776</td>\n",
       "      <td>1125</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20250</th>\n",
       "      <td>350 dot org</td>\n",
       "      <td>350</td>\n",
       "      <td>en</td>\n",
       "      <td>1153</td>\n",
       "      <td>25876</td>\n",
       "      <td>19502</td>\n",
       "      <td>Join a global movement that's inspiring the wo...</td>\n",
       "      <td>266424</td>\n",
       "      <td>http://www.twitter.com/350</td>\n",
       "      <td>5870</td>\n",
       "      <td>True</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name      screen_name lang  favourites_count  \\\n",
       "20246                DOSE       ___Dose___   en                 8   \n",
       "20247  One Direction News  _______1d_4ever   en                 0   \n",
       "20248         Tyrne Clark         10223335   en               467   \n",
       "20249                1776             1776   en              6586   \n",
       "20250         350 dot org              350   en              1153   \n",
       "\n",
       "       statuses_count  friends_count  \\\n",
       "20246           20194             12   \n",
       "20247           18578          37552   \n",
       "20248           13481          60692   \n",
       "20249            9746           1293   \n",
       "20250           25876          19502   \n",
       "\n",
       "                                                 summary  followers_count  \\\n",
       "20246  A Strong Dose of Amazing People, Places, and T...           421003   \n",
       "20247  All the latest One Direction news from around ...            46205   \n",
       "20248  Shouldn't a strange and wonderful world be ful...            58620   \n",
       "20249  Global incubator & seed fund helping startups ...            87459   \n",
       "20250  Join a global movement that's inspiring the wo...           266424   \n",
       "\n",
       "                                         link  listed_count verified segment  \\\n",
       "20246       http://www.twitter.com/___Dose___          2949    False  person   \n",
       "20247  http://www.twitter.com/_______1d_4ever            46    False  person   \n",
       "20248         http://www.twitter.com/10223335            54    False  person   \n",
       "20249             http://www.twitter.com/1776          1125    False  person   \n",
       "20250              http://www.twitter.com/350          5870     True  person   \n",
       "\n",
       "       manual_segment  \n",
       "20246               0  \n",
       "20247               0  \n",
       "20248               1  \n",
       "20249               0  \n",
       "20250               0  "
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>manual_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19844.000000</td>\n",
       "      <td>20202.000000</td>\n",
       "      <td>20197.000000</td>\n",
       "      <td>20210.000000</td>\n",
       "      <td>20054.000000</td>\n",
       "      <td>20245.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6692.418766</td>\n",
       "      <td>43975.199733</td>\n",
       "      <td>25278.933951</td>\n",
       "      <td>253485.692528</td>\n",
       "      <td>1416.983445</td>\n",
       "      <td>0.533169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21818.175658</td>\n",
       "      <td>86934.198698</td>\n",
       "      <td>54323.166270</td>\n",
       "      <td>1394969.623505</td>\n",
       "      <td>6657.741655</td>\n",
       "      <td>0.498911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1356.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>5968.250000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>54386.750000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>851.000000</td>\n",
       "      <td>17870.500000</td>\n",
       "      <td>2436.000000</td>\n",
       "      <td>81605.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4435.000000</td>\n",
       "      <td>46988.000000</td>\n",
       "      <td>33541.000000</td>\n",
       "      <td>156324.750000</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>685477.000000</td>\n",
       "      <td>2372600.000000</td>\n",
       "      <td>1004606.000000</td>\n",
       "      <td>77803396.000000</td>\n",
       "      <td>626947.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       favourites_count  statuses_count   friends_count  followers_count  \\\n",
       "count      19844.000000    20202.000000    20197.000000     20210.000000   \n",
       "mean        6692.418766    43975.199733    25278.933951    253485.692528   \n",
       "std        21818.175658    86934.198698    54323.166270   1394969.623505   \n",
       "min            0.000000        1.000000    -1356.000000         3.000000   \n",
       "25%           88.000000     5968.250000      458.000000     54386.750000   \n",
       "50%          851.000000    17870.500000     2436.000000     81605.000000   \n",
       "75%         4435.000000    46988.000000    33541.000000    156324.750000   \n",
       "max       685477.000000  2372600.000000  1004606.000000  77803396.000000   \n",
       "\n",
       "        listed_count  manual_segment  \n",
       "count   20054.000000    20245.000000  \n",
       "mean     1416.983445        0.533169  \n",
       "std      6657.741655        0.498911  \n",
       "min         0.000000        0.000000  \n",
       "25%       107.000000        0.000000  \n",
       "50%       359.000000        1.000000  \n",
       "75%      1198.000000        1.000000  \n",
       "max    626947.000000        1.000000  "
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"summary\"] = train[\"summary\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When summary contains my  958 (80.4%) are person\n",
      "When summary contains myself 29 (93.5%) are person\n",
      "When summary contains husband 61 (92.4%) are person\n",
      "When summary contains wife 45 (95.7%) are person\n",
      "When summary contains father 79 (90.8%) are person\n",
      "When summary contains mother 29 (93.5%) are person\n",
      "When summary contains entrepreneur  33 (86.8%) are person\n",
      "When summary contains scientist 15 (78.9%) are person\n",
      "When summary contains CEO 317 (86.8%) are person\n",
      "When summary contains chief 13 (76.5%) are person\n",
      "When summary contains guitar 20 (87.0%) are person\n"
     ]
    }
   ],
   "source": [
    "relevance_margin = 25\n",
    "relevance_count = 10\n",
    "\n",
    "summary_words = [\"organization\", \"institute\", \"institution\", \n",
    "                 \"my \", \"myself\", \n",
    "                 \"financial\", \"money\", \"social\",\n",
    "                 \"family\", \"husband\", \"wife\", \"father\", \"mother\", \"kids\", \"children\", \n",
    "                 \"entrepreneur \", \"scientist\", \"CEO\", \"CTO \", \"CPO\",\n",
    "                 \"chief\", \"leader\", \"industry\", \"engineer \", \"musician \", \"piano \", \"guitar\"]\n",
    "\n",
    "for word in summary_words:\n",
    "    counts = train[train['summary'].str.contains(word)][\"manual_segment\"].value_counts()\n",
    "    n_is_person = counts[1]\n",
    "    p_is_person = round(float(n_is_person)/sum(counts)*100,1)\n",
    "    \n",
    "    if (p_is_person > (100 - relevance_margin) or p_is_person < relevance_margin) and n_is_person >= relevance_count:\n",
    "        print \"When summary contains {} {} ({}%) are person\".format(word, n_is_person, p_is_person)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.drop([\"segment\"], axis=1)\n",
    "train = train.drop([\"link\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, nan, True]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(train.verified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train.verified.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.ix[train.verified.isnull(), 'verified'] = False\n",
    "train.ix[train.verified == True,  'verified'] = 1\n",
    "train.ix[train.verified == False, 'verified'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(train.verified))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoding for lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simple manual OHE\n",
    "if \"lang\" in train:\n",
    "    train.ix[(train.lang == 'Select Language...') | (train.lang.isnull()), 'lang'] = None\n",
    "    for lang in list(set(train.lang)):\n",
    "        if lang != None:\n",
    "            train.ix[train.lang == lang, \"lang_\"+lang] = 1\n",
    "            train.ix[train.lang != lang, \"lang_\"+lang] = 0\n",
    "    train.drop([\"lang\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1298"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fields = [\"name\", \"screen_name\",\"summary\"]\n",
    "\n",
    "def treat_special_char(c):\n",
    "    try:\n",
    "        encoding = chardet.detect(str(c))['encoding'] or \"KOI8-R\"\n",
    "        return '0' if c.isdigit() else c.decode(encoding)\n",
    "    except UnicodeDecodeError:        \n",
    "        return '9'\n",
    "\n",
    "for field in text_fields:\n",
    "    train.ix[train[field].isnull(), field] = \"null\"\n",
    "    train[field] = map(lambda n: ''.join(map(lambda c: treat_special_char(c), list(n))), train[field].values)\n",
    "    \n",
    "train[text_fields].head()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer for 'screen_name' and 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20245, 1107)\n",
      "(20239, 1148)\n",
      "(20239, 1581)\n",
      "(20233, 2728)\n"
     ]
    }
   ],
   "source": [
    "def num_char_tokenizer(text):\n",
    "    return list(text)\n",
    "\n",
    "for field in [\"screen_name\",\"name\"]:\n",
    "    if field in train:\n",
    "\n",
    "        field_tfidf = TfidfVectorizer(tokenizer=num_char_tokenizer,\n",
    "                                      ngram_range=(3, 5), \n",
    "                                      analyzer=\"char\",\n",
    "                                      binary=True, #False\n",
    "                                      min_df = 50) #8\n",
    "\n",
    "        field_matrix = field_tfidf.fit_transform(train[field])\n",
    "        features_names = map(lambda f: \"_\".join([field,f]), field_tfidf.get_feature_names())\n",
    "        field_df = pd.DataFrame(field_matrix.A, columns=features_names)\n",
    "        print(field_matrix.shape)\n",
    "        gc.collect()\n",
    "\n",
    "        train = pd.concat([train, field_df], axis=1, join='inner')\n",
    "        gc.collect()\n",
    "        train.drop([field], axis=1, inplace=True)\n",
    "        gc.collect()\n",
    "        print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer for 'summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20233, 748)\n",
      "(20227, 3475)\n"
     ]
    }
   ],
   "source": [
    "if \"summary\" in train:\n",
    "\n",
    "    summary_tfidf = TfidfVectorizer(token_pattern=r'\\w+',\n",
    "                                    ngram_range=(1, 4), \n",
    "                                    analyzer=\"word\",\n",
    "                                    binary=True, #False\n",
    "                                    sublinear_tf=True, \n",
    "                                    stop_words='english',\n",
    "                                    min_df = 50) #5\n",
    "\n",
    "    summary_matrix = summary_tfidf.fit_transform(train.summary)\n",
    "    features_names = map(lambda f: \"_\".join([\"summary\",f]), summary_tfidf.get_feature_names())\n",
    "    summary_df = pd.DataFrame(summary_matrix.A, columns=features_names)\n",
    "    print(summary_matrix.shape)\n",
    "    train = pd.concat([train, summary_df], axis=1, join='inner').drop([\"summary\"], axis=1)\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist Enriched Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/manually_categorized/actor_classification_random_forest_features_20151124.csv']"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.to_csv('data/manually_categorized/enriched-actor_classification_train.csv', index=False, encoding=\"utf-8\")\n",
    "joblib.dump(train.columns, 'data/manually_categorized/actor_classification_random_forest_features_20151124.csv', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome = \"manual_segment\"\n",
    "\n",
    "features = list(set(train.columns) - set([outcome]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Build estimator from PCA and Univariate selection:\n",
    "# combined_features = FeatureUnion([(\"pca\", PCA(n_components=2)), \n",
    "#                                   (\"univ_select\", SelectKBest(k=1))])\n",
    "\n",
    "# tr   = np.asarray(train[features])\n",
    "# tr_y = np.asarray(train[outcome])\n",
    "\n",
    "# # Use combined features to transform dataset\n",
    "# X_features = combined_features.fit(tr, tr_y).transform(tr)\n",
    "\n",
    "# # Random Forest model\n",
    "# rfmodel = RandomForestClassifier(n_estimators=25)\n",
    "\n",
    "# # Do grid search over k, n_components and C:\n",
    "# pipeline = Pipeline([(\"features\", combined_features), (\"rf\", rfmodel)])\n",
    "\n",
    "# param_dist = dict(features__pca__n_components=range(50, 500),\n",
    "#                   features__univ_select__k=range(50, 500))\n",
    "\n",
    "# random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, verbose=10,\n",
    "#                                    n_iter=200)\n",
    "# random_search.fit(tr, tr_y)\n",
    "# print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1354  960]\n",
      " [ 841 1902]]\n",
      "score:0.643859996045\n",
      "[[1365 1043]\n",
      " [ 762 1887]]\n",
      "score:0.643069013249\n",
      "[[1390  999]\n",
      " [ 764 1904]]\n",
      "score:0.651374332608\n",
      "[[1342  989]\n",
      " [ 798 1927]]\n",
      "score:0.646558544304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/cross_validation.py:69: DeprecationWarning: The indices parameter is deprecated and will be removed (assumed True) in 0.17\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# KFold cross validation setup\n",
    "k_fold = KFold(n=len(train), n_folds=4, indices=False, shuffle=True)\n",
    "b_scores, svc_scores = [], []\n",
    "\n",
    "for tr_indices, cv_indices in k_fold:\n",
    "    tr   = np.asarray(train[tr_indices][features])\n",
    "    tr_y = np.asarray(train[tr_indices][outcome])\n",
    "    \n",
    "    cv   = np.asarray(train[cv_indices][features])\n",
    "    cv_y = np.asarray(train[cv_indices][outcome])\n",
    "    \n",
    "    # StandardScaler\n",
    "    scaler = StandardScaler().fit(tr)    \n",
    "    tr = scaler.transform(tr)\n",
    "\n",
    "    # Random Forest model\n",
    "    rfmodel = RandomForestClassifier(n_estimators=100)\n",
    "    rfmodel.fit(tr, tr_y)\n",
    "\n",
    "    # Validate\n",
    "    cv = scaler.transform(cv)\n",
    "    print(confusion_matrix(cv_y, rfmodel.predict(cv)))    \n",
    "    print('score:' + str(rfmodel.score(cv, cv_y)))\n",
    "    \n",
    "rfmodel = RandomForestClassifier(n_estimators=100)\n",
    "rfmodel.fit(train[features], train[outcome])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist model and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = \"data/manually_categorized/actor_classification_random_forest_20151129.pkl\"\n",
    "model_features_path = \"data/manually_categorized/actor_classification_random_forest_features_20151129.pkl\"\n",
    "\n",
    "joblib.dump(rfmodel, model_path, compress=9)\n",
    "joblib.dump(train.columns, model_features_path, compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model = joblib.load(glob.glob(model_path))\n",
    "model_features = joblib.load(glob.glob(model_features_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = ['{\"name\":\"Светлана Петухова\",\"screen_name\":\"svpetuhova26623\",\"summary\":\"\",\"lang\":\"ru\",\"favourites_count\":23,\"statuses_count\":14,\"friends_count\":2,\"followers_count\":1,\"listed_count\":1,\"verified\":0}',\n",
    "             '{\"lang\":\"en\",\"summary\":\"Artist, Writer, Designer. Tweets on tech, culture, art, animals, love the socioeconomy.\",\"verified\":0,\"followers_count\":175,\"friends_count\":397,\"favourites_count\":228,\"statuses_count\":410,\"listed_count\":12,\"name\":\"Daniel Adornes\",\"screen_name\":\"daniel_adornes\"}',\n",
    "             '{\"lang\":\"en\",\"summary\":\"Artist, Writer, Designer. Tweets on tech, culture, art, animals, love the socioeconomy.\",\"verified\":0,\"followers_count\":175,\"friends_count\":397,\"favourites_count\":228,\"statuses_count\":410,\"listed_count\":12,\"name\":\"Daniel Adornes\",\"screen_name\":\"daniel_adornes\"}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = [json.loads(t) for t in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.ix[test_data.verified.isnull(), 'verified'] = False\n",
    "test_data.ix[test_data.verified == True,  'verified'] = 1\n",
    "test_data.ix[test_data.verified == False, 'verified'] = 0\n",
    "\n",
    "# 'lang'\n",
    "for lang_field in filter(lambda f: f.startswith(\"lang_\"), self.model_features):\n",
    "  test_data[lang_field] = (1 if lang_field == \"lang_\"+(test_data[\"lang\"]).values[0] else 0)\n",
    "del test_data[\"lang\"]\n",
    "\n",
    "# Treat special characters\n",
    "text_fields = [\"name\", \"screen_name\",\"summary\"]\n",
    "\n",
    "def treat_special_char(c):\n",
    "  try:\n",
    "    encoding = chardet.detect(str(c))['encoding'] or \"KOI8-R\"\n",
    "    return '0' if c.isdigit() else c.decode(encoding)\n",
    "  except:\n",
    "    return '9'\n",
    "\n",
    "for field in text_fields:\n",
    "  test_data.ix[test_data[field].isnull(), field] = \"null\"\n",
    "  test_data[field] = map(lambda n: ''.join(map(lambda c: treat_special_char(c), list(n))), test_data[field].values)\n",
    "\n",
    "# TfidfVectorizer for 'screen_name' and 'name'\n",
    "def num_char_tokenizer(text):\n",
    "  return list(text)\n",
    "\n",
    "for field in [\"screen_name\",\"name\"]:\n",
    "  if field in test_data:\n",
    "    vocabulary = [f.replace(field+\"_\", \"\") for f in self.model_features if f.startswith(field+\"_\")]\n",
    "    field_tfidf = TfidfVectorizer(tokenizer=num_char_tokenizer,\n",
    "                                  ngram_range=(3, 5), \n",
    "                                  analyzer=\"char\",\n",
    "                                  vocabulary = vocabulary)\n",
    "\n",
    "    field_matrix = field_tfidf.fit_transform(test_data[field])\n",
    "    features_names = map(lambda f: \"_\".join([field,f]), field_tfidf.get_feature_names())\n",
    "    field_df = pd.test_DataFrame(field_matrix.A, columns=features_names)\n",
    "    gc.collect()\n",
    "    test_data = pd.concat([test_data, field_df], axis=1, join='inner')\n",
    "    del test_data[field]\n",
    "    gc.collect()\n",
    "\n",
    "# TfidfVectorizer for 'summary'\n",
    "if \"summary\" in test_data:\n",
    "  vocabulary = [f.replace(\"summary_\", \"\") for f in self.model_features if f.startswith(\"summary_\")]\n",
    "  summary_tfidf = TfidfVectorizer(token_pattern=r'\\w+',\n",
    "                                  ngram_range=(1, 4), \n",
    "                                  analyzer=\"word\",\n",
    "                                  binary=True, #False \n",
    "                                  stop_words='english',\n",
    "                                  vocabulary = vocabulary)\n",
    "\n",
    "  summary_matrix = summary_tfidf.fit_transform(test_data.summary)\n",
    "  features_names = map(lambda f: \"_\".join([\"summary\",f]), summary_tfidf.get_feature_names())\n",
    "  summary_df = pd.test_DataFrame(summary_matrix.A, columns=features_names)\n",
    "  gc.collect()\n",
    "  test_data = pd.concat([test_data, summary_df], axis=1, join='inner')\n",
    "  del test_data[\"summary\"]\n",
    "  gc.collect()\n",
    "\n",
    "# Treat remaining null values\n",
    "test_data.fillna(0, inplace=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model.predict_proba(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
