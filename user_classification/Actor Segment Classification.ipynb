{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.decomposition import PCA, RandomizedPCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initializing input dataframe: \n",
      "(20245, 13)\n",
      "==> Concatenating dataframe from actor_classification_train_copy.csv: \n",
      "(20245, 13)\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'data/manually_categorized/'\n",
    "input_prefix = 'actor_classification_train'\n",
    "train = None\n",
    "for file in os.listdir(input_dir):\n",
    "  if fnmatch.fnmatch(file, input_prefix+'*.csv'):\n",
    "    if train is None:\n",
    "      print \"==> Initializing input dataframe: \"\n",
    "      train = pd.read_csv(open(input_dir+file,'rU'),\n",
    "                          engine='python', sep=\",\", quoting=1)\n",
    "    else:\n",
    "      print \"==> Concatenating dataframe from \" + file + \": \"\n",
    "      train = pd.concat([train, pd.read_csv(open(input_dir+file,'rU'),\n",
    "                          engine='python', sep=\",\", quoting=1)])\n",
    "    train.drop_duplicates(inplace=True)\n",
    "    print train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>summary</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>link</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>segment</th>\n",
       "      <th>manual_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>仆���Peace God 仆��� Payne</td>\n",
       "      <td>Rudeboynookie</td>\n",
       "      <td>en</td>\n",
       "      <td>1314</td>\n",
       "      <td>56792</td>\n",
       "      <td>34235</td>\n",
       "      <td>#Artist #Father #artist #Promoter #PeaceGod #N...</td>\n",
       "      <td>55061</td>\n",
       "      <td>http://www.twitter.com/Rudeboynookie</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20168</th>\n",
       "      <td>Mansoor Ali Khan</td>\n",
       "      <td>_Mans00r</td>\n",
       "      <td>en</td>\n",
       "      <td>9238</td>\n",
       "      <td>2224</td>\n",
       "      <td>980</td>\n",
       "      <td>Senior Anchor/Journalist/Blogger, ICFJ fellow,...</td>\n",
       "      <td>234322</td>\n",
       "      <td>http://www.twitter.com/_Mans00r</td>\n",
       "      <td>562</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>Marco Staff</td>\n",
       "      <td>MarcoStaff</td>\n",
       "      <td>en</td>\n",
       "      <td>860</td>\n",
       "      <td>6362</td>\n",
       "      <td>15436</td>\n",
       "      <td>Owner &amp; Creator of Expensiv Lifestyle.</td>\n",
       "      <td>40736</td>\n",
       "      <td>http://www.twitter.com/MarcoStaff</td>\n",
       "      <td>110</td>\n",
       "      <td>False</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16957</th>\n",
       "      <td>Christine Gilbert</td>\n",
       "      <td>cb_gilbert</td>\n",
       "      <td>en</td>\n",
       "      <td>768</td>\n",
       "      <td>12027</td>\n",
       "      <td>842</td>\n",
       "      <td>Writer, Photographer &amp; Filmmaker. Wife of the ...</td>\n",
       "      <td>45229</td>\n",
       "      <td>http://www.twitter.com/cb_gilbert</td>\n",
       "      <td>2070</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>Andrea Lowell</td>\n",
       "      <td>TheAndreaLowell</td>\n",
       "      <td>en</td>\n",
       "      <td>40</td>\n",
       "      <td>5198</td>\n",
       "      <td>447</td>\n",
       "      <td>TV &amp; Radio Host, Model, and Raw Superfood Enth...</td>\n",
       "      <td>41204</td>\n",
       "      <td>http://www.twitter.com/TheAndreaLowell</td>\n",
       "      <td>432</td>\n",
       "      <td>False</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name      screen_name lang  favourites_count  \\\n",
       "5036   仆���Peace God 仆��� Payne    Rudeboynookie   en              1314   \n",
       "20168          Mansoor Ali Khan         _Mans00r   en              9238   \n",
       "9009                Marco Staff       MarcoStaff   en               860   \n",
       "16957         Christine Gilbert       cb_gilbert   en               768   \n",
       "2777              Andrea Lowell  TheAndreaLowell   en                40   \n",
       "\n",
       "       statuses_count  friends_count  \\\n",
       "5036            56792          34235   \n",
       "20168            2224            980   \n",
       "9009             6362          15436   \n",
       "16957           12027            842   \n",
       "2777             5198            447   \n",
       "\n",
       "                                                 summary  followers_count  \\\n",
       "5036   #Artist #Father #artist #Promoter #PeaceGod #N...            55061   \n",
       "20168  Senior Anchor/Journalist/Blogger, ICFJ fellow,...           234322   \n",
       "9009              Owner & Creator of Expensiv Lifestyle.            40736   \n",
       "16957  Writer, Photographer & Filmmaker. Wife of the ...            45229   \n",
       "2777   TV & Radio Host, Model, and Raw Superfood Enth...            41204   \n",
       "\n",
       "                                         link  listed_count verified  \\\n",
       "5036     http://www.twitter.com/Rudeboynookie            82    False   \n",
       "20168         http://www.twitter.com/_Mans00r           562    False   \n",
       "9009        http://www.twitter.com/MarcoStaff           110    False   \n",
       "16957       http://www.twitter.com/cb_gilbert          2070    False   \n",
       "2777   http://www.twitter.com/TheAndreaLowell           432    False   \n",
       "\n",
       "        segment  manual_segment  \n",
       "5036     person               0  \n",
       "20168    person               1  \n",
       "9009   business               0  \n",
       "16957    person               1  \n",
       "2777   business               0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sample(1000)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>summary</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>link</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>segment</th>\n",
       "      <th>manual_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>Sean Melvin</td>\n",
       "      <td>ThatBlokeSean</td>\n",
       "      <td>en</td>\n",
       "      <td>5081</td>\n",
       "      <td>60040</td>\n",
       "      <td>162300</td>\n",
       "      <td>Financial Systems Consultant, Business Start U...</td>\n",
       "      <td>163176</td>\n",
       "      <td>http://www.twitter.com/ThatBlokeSean</td>\n",
       "      <td>1350</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8218</th>\n",
       "      <td>�ʙ�����</td>\n",
       "      <td>mo__la</td>\n",
       "      <td>ar</td>\n",
       "      <td>295</td>\n",
       "      <td>81724</td>\n",
       "      <td>161669</td>\n",
       "      <td>���� �����_�� �_���� �����_��</td>\n",
       "      <td>159778</td>\n",
       "      <td>http://www.twitter.com/mo__la</td>\n",
       "      <td>212</td>\n",
       "      <td>False</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9823</th>\n",
       "      <td>LeBron James �_</td>\n",
       "      <td>LeBronJames</td>\n",
       "      <td>en</td>\n",
       "      <td>1135</td>\n",
       "      <td>1115</td>\n",
       "      <td>806213</td>\n",
       "      <td>��� #StriveForGreatness��_����_ #TeamLeBron pa...</td>\n",
       "      <td>3096517</td>\n",
       "      <td>http://www.twitter.com/LeBronJames</td>\n",
       "      <td>876</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>Exotic cars for sale</td>\n",
       "      <td>theBestOfCars</td>\n",
       "      <td>en</td>\n",
       "      <td>20</td>\n",
       "      <td>254</td>\n",
       "      <td>95</td>\n",
       "      <td>A secret exotic car community</td>\n",
       "      <td>35066</td>\n",
       "      <td>http://www.twitter.com/theBestOfCars</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16518</th>\n",
       "      <td>IG: ClayPerryMusic</td>\n",
       "      <td>ClayPerryMusic</td>\n",
       "      <td>en</td>\n",
       "      <td>20579</td>\n",
       "      <td>61698</td>\n",
       "      <td>27604</td>\n",
       "      <td>Recording Artist | Assistant: @MikeJQuintero |...</td>\n",
       "      <td>61973</td>\n",
       "      <td>http://www.twitter.com/ClayPerryMusic</td>\n",
       "      <td>93</td>\n",
       "      <td>False</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name     screen_name lang  favourites_count  \\\n",
       "2837            Sean Melvin   ThatBlokeSean   en              5081   \n",
       "8218                �ʙ�����          mo__la   ar               295   \n",
       "9823        LeBron James �_     LeBronJames   en              1135   \n",
       "2755   Exotic cars for sale   theBestOfCars   en                20   \n",
       "16518    IG: ClayPerryMusic  ClayPerryMusic   en             20579   \n",
       "\n",
       "       statuses_count  friends_count  \\\n",
       "2837            60040         162300   \n",
       "8218            81724         161669   \n",
       "9823             1115         806213   \n",
       "2755              254             95   \n",
       "16518           61698          27604   \n",
       "\n",
       "                                                 summary  followers_count  \\\n",
       "2837   Financial Systems Consultant, Business Start U...           163176   \n",
       "8218                       ���� �����_�� �_���� �����_��           159778   \n",
       "9823   ��� #StriveForGreatness��_����_ #TeamLeBron pa...          3096517   \n",
       "2755                       A secret exotic car community            35066   \n",
       "16518  Recording Artist | Assistant: @MikeJQuintero |...            61973   \n",
       "\n",
       "                                        link  listed_count verified   segment  \\\n",
       "2837    http://www.twitter.com/ThatBlokeSean          1350    False    person   \n",
       "8218           http://www.twitter.com/mo__la           212    False  business   \n",
       "9823      http://www.twitter.com/LeBronJames           876    False    person   \n",
       "2755    http://www.twitter.com/theBestOfCars            96    False  business   \n",
       "16518  http://www.twitter.com/ClayPerryMusic            93    False    person   \n",
       "\n",
       "       manual_segment  \n",
       "2837                1  \n",
       "8218                0  \n",
       "9823                1  \n",
       "2755                0  \n",
       "16518               1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformer with LabelEncoder for 'verified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VerifiedTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X.verified.fillna(False, inplace=True)\n",
    "        X.verified = LabelEncoder().fit_transform(X.verified)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    849\n",
      "1    151\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "verified_transformer = VerifiedTransformer()\n",
    "verified_transformer.transform(train)\n",
    "\n",
    "print train.verified.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom OneHotEncoding for lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LangOneHotEncoding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        valid_langs = list(set(X.lang) - set([None, np.nan, 'Select Language...']))\n",
    "        self.feature_names_ = [\"lang_\"+l for l in valid_langs]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        check_is_fitted(self, 'feature_names_')\n",
    "        \n",
    "        X[\"lang\"].fillna(\"\", inplace=True)\n",
    "        for lang_feature in self.feature_names_:\n",
    "            X[lang_feature] = [(1 if lang_feature == \"lang_\"+v else 0) for v in X[\"lang\"].values]\n",
    "        \n",
    "        X.drop([\"lang\"], axis=1, inplace=True)\n",
    "        return X\n",
    "    \n",
    "lang_ohe = LangOneHotEncoding().fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special characters Transformation [DELETE AFTER EVERYTHING WORKS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class SpecialCharactersTransformer(TransformerMixin):\n",
    "\n",
    "#     def __init__(self, text_fields):\n",
    "#         self.text_fields = text_fields\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def treat_special_char(self, c):\n",
    "#         try:\n",
    "#             encoding = chardet.detect(str(c))['encoding'] or \"KOI8-R\"\n",
    "#             return '0' if c.isdigit() else c.decode(encoding)\n",
    "#         except UnicodeDecodeError:        \n",
    "#             return '9'\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "#         for field in self.text_fields:\n",
    "# #             X.ix[X[field].isnull(), field] = \"null\"\n",
    "# #             X[field] = map(lambda n: ''.join(map(lambda c: self.treat_special_char(c), list(n))), X[field].values)\n",
    "#             X[field].fillna(\"null\", inplace=True)\n",
    "#             X[field] = [''.join([self.treat_special_char(c) for c in list(n)]) for n in X[field].values]\n",
    "\n",
    "#         return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameTfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataFrameTfidfVectorizer(TfidfVectorizer):\n",
    "\n",
    "    def __init__(self, col, input='content', encoding='utf-8',\n",
    "                 decode_error='strict', strip_accents=None, lowercase=True,\n",
    "                 preprocessor=None, tokenizer=None, analyzer='word',\n",
    "                 stop_words=None, token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "                 ngram_range=(1, 1), max_df=1.0, min_df=1,\n",
    "                 max_features=None, vocabulary=None, binary=False,\n",
    "                 dtype=np.int64, norm='l2', use_idf=True, smooth_idf=True,\n",
    "                 sublinear_tf=False):\n",
    "        super(DataFrameTfidfVectorizer, self).__init__(\n",
    "            input=input, encoding=encoding, decode_error=decode_error,\n",
    "            strip_accents=strip_accents, lowercase=lowercase,\n",
    "            preprocessor=preprocessor, tokenizer=tokenizer, analyzer=analyzer,\n",
    "            stop_words=stop_words, token_pattern=token_pattern,\n",
    "            ngram_range=ngram_range, max_df=max_df, min_df=min_df,\n",
    "            max_features=max_features, vocabulary=vocabulary, binary=binary,\n",
    "            dtype=dtype)\n",
    "\n",
    "        self.col = col\n",
    "        \n",
    "    def treat_special_char(self, c):\n",
    "        try:\n",
    "            encoding = chardet.detect(str(c))['encoding'] or \"KOI8-R\"\n",
    "            return '0' if c.isdigit() else c.decode(encoding)\n",
    "        except:        \n",
    "            return '9'\n",
    "\n",
    "    def treat_special_chars(self, col):\n",
    "        col.fillna(\"null\", inplace=True)\n",
    "        col = [''.join([self.treat_special_char(c) for c in list(n)]) \n",
    "               for n in col.values]\n",
    "        return col\n",
    "\n",
    "    def fit(self, dataframe, y=None):\n",
    "        dataframe[self.col] = self.treat_special_chars(dataframe[self.col])\n",
    "        super(DataFrameTfidfVectorizer, self).fit(dataframe[self.col])\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, dataframe, y=None):\n",
    "        dataframe[self.col] = self.treat_special_chars(dataframe[self.col])\n",
    "        field_matrix = super(DataFrameTfidfVectorizer, self).fit_transform(dataframe[self.col])\n",
    "        features_names = map(lambda f: \"_\".join([self.col,f]), super(DataFrameTfidfVectorizer, self).get_feature_names())\n",
    "        field_df = pd.DataFrame(field_matrix.A, columns=features_names)\n",
    "\n",
    "        dataframe = dataframe.join(field_df)\n",
    "        dataframe.drop([self.col], axis=1, inplace=True)\n",
    "\n",
    "        return dataframe\n",
    "\n",
    "    def transform(self, dataframe, copy=True):\n",
    "        dataframe[self.col] = self.treat_special_chars(dataframe[self.col])\n",
    "        field_matrix = super(DataFrameTfidfVectorizer, self).transform(dataframe[self.col])\n",
    "        features_names = map(lambda f: \"_\".join([self.col,f]), super(DataFrameTfidfVectorizer, self).get_feature_names())\n",
    "        field_df = pd.DataFrame(field_matrix.A, columns=features_names)\n",
    "\n",
    "        dataframe = dataframe.join(field_df)\n",
    "        dataframe.drop([self.col], axis=1, inplace=True)\n",
    "\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameTfidfVectorizer for textual fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_tfidf = DataFrameTfidfVectorizer(col=\"name\", \n",
    "                                      ngram_range=(3, 5), \n",
    "                                      analyzer=\"char\",\n",
    "                                      binary=True, #False\n",
    "                                      min_df = 5) #8\n",
    "\n",
    "screen_name_tfidf = DataFrameTfidfVectorizer(col=\"screen_name\", \n",
    "                                             ngram_range=(3, 5), \n",
    "                                             analyzer=\"char\",\n",
    "                                             binary=True, #False\n",
    "                                             min_df = 5) #8\n",
    "\n",
    "summary_tfidf = DataFrameTfidfVectorizer(col=\"summary\",\n",
    "                                         token_pattern=r'\\w+',\n",
    "                                         ngram_range=(1, 3), \n",
    "                                         analyzer=\"word\",\n",
    "                                         binary=True, #False\n",
    "                                         sublinear_tf=True, \n",
    "                                         stop_words='english',\n",
    "                                         min_df = 5) #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrameTfidfVectorizer(analyzer='word', binary=True, col='summary',\n",
       "             decode_error='strict', dtype=<type 'numpy.int64'>,\n",
       "             encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "             max_features=None, min_df=5, ngram_range=(1, 3), norm=u'l2',\n",
       "             preprocessor=None, smooth_idf=True, stop_words='english',\n",
       "             strip_accents=None, sublinear_tf=False, token_pattern='\\\\w+',\n",
       "             tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_tfidf.fit(train)\n",
    "screen_name_tfidf.fit(train)\n",
    "summary_tfidf.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Columns Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DropColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        for c in self.cols:\n",
    "            if c in X:\n",
    "                X.drop([c], axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Imputer and np array transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NumpyArrayTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X.fillna(0, inplace=True)\n",
    "        return np.asarray(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Debugger for pipeline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Debugger(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print \"-------------------------\"\n",
    "        print type(X)\n",
    "        print \"-------------------------\"\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome = \"manual_segment\"\n",
    "\n",
    "features = list(set(train.columns) - set([outcome]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## KFold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.KFold(n=1000, n_folds=2, shuffle=True, random_state=None)\n",
      "-------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "-------------------------\n",
      "-------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "-------------------------\n",
      "-------------------------\n",
      "<type 'numpy.ndarray'>\n",
      "-------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'verified'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9d8697503bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/utils/metaestimators.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-40edcd87c2e7>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'verified'"
     ]
    }
   ],
   "source": [
    "doCV = True\n",
    "\n",
    "if doCV:\n",
    "    # KFold cross validation setup\n",
    "    k_fold = KFold(n=len(train), n_folds=2, shuffle=True)\n",
    "    b_scores, svc_scores = [], []\n",
    "\n",
    "    n_estimators = 10\n",
    "\n",
    "    for tr_indices, cv_indices in k_fold:\n",
    "        \n",
    "        print k_fold\n",
    "        \n",
    "        tr    = train.iloc[tr_indices,:].loc[:, features].copy()\n",
    "        cv    = train.iloc[cv_indices,:].loc[:, features].copy()\n",
    "        \n",
    "        tr_y  = np.asarray(tr_cv.loc[tr_indices][outcome].values)\n",
    "        cv_y  = np.asarray(tr_cv.loc[cv_indices][outcome].values)\n",
    "\n",
    "        # Model Pipeline\n",
    "        model = Pipeline([(\"drop_cols\", DropColumnsTransformer([\"segment\",\"link\"])),\n",
    "                          (\"debugger\", Debugger()),\n",
    "                          (\"verified\", VerifiedTransformer()),\n",
    "                          (\"lang\", lang_ohe),\n",
    "                          (\"name_tfidf\", name_tfidf),\n",
    "                          (\"screen_name_tfidf\", screen_name_tfidf),\n",
    "                          (\"summary_tfidf\", summary_tfidf),\n",
    "                          (\"nparray\", NumpyArrayTransformer()),\n",
    "                          (\"scaler\", StandardScaler()),\n",
    "                          (\"rf\", RandomForestClassifier())])\n",
    "        model.set_params(rf__n_estimators = n_estimators)\n",
    "\n",
    "        model.fit(tr, tr_y)\n",
    "\n",
    "        # Validate\n",
    "        cv = model.transform(cv)\n",
    "        print(confusion_matrix(cv_y, model.predict(cv)))    \n",
    "        print('score:' + str(model.score(cv, cv_y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('drop_cols', DropColumnsTransformer(cols=['segment', 'link'])), ('verified', VerifiedTransformer()), ('lang', LangOneHotEncoding()), ('name_tfidf', DataFrameTfidfVectorizer(analyzer='char', binary=True, col='name',\n",
       "             decode_error='strict', dtype=<type 'numpy.int64'>,\n",
       "             ...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([(\"drop_cols\", DropColumnsTransformer([\"segment\",\"link\"])),\n",
    "                  (\"verified\", VerifiedTransformer()),\n",
    "                  (\"lang\", lang_ohe),\n",
    "                  (\"name_tfidf\", name_tfidf),\n",
    "                  (\"screen_name_tfidf\", screen_name_tfidf),\n",
    "                  (\"summary_tfidf\", summary_tfidf),\n",
    "                  (\"nparray\", NumpyArrayTransformer()),\n",
    "                  (\"scaler\", StandardScaler()),\n",
    "                  (\"rf\", RandomForestClassifier())])\n",
    "model.set_params(rf__n_estimators = n_estimators)\n",
    "model.fit(train.loc[:,features], train.loc[:,outcome])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/manually_categorized/actor_classification_random_forest_20151129.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"data/manually_categorized/actor_classification_random_forest_20151129.pkl\"\n",
    "joblib.dump(model, model_path, compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = ['{\"name\":\"Светлана Петухова\",\"screen_name\":\"svpetuhova26623\",\"summary\":\"\",\"lang\":\"ru\",\"favourites_count\":23,\"statuses_count\":14,\"friends_count\":2,\"followers_count\":1,\"listed_count\":1,\"verified\":0}',\n",
    "             '{\"lang\":\"en\",\"summary\":\"Artist, Writer, Designer. Tweets on tech, culture, art, animals, love the socioeconomy.\",\"verified\":0,\"followers_count\":175,\"friends_count\":397,\"favourites_count\":228,\"statuses_count\":410,\"listed_count\":12,\"name\":\"Daniel Adornes\",\"screen_name\":\"daniel_adornes\"}',\n",
    "             '{\"lang\":\"en\",\"summary\":\"Artist, Writer, Designer. Tweets on tech, culture, art, animals, love the socioeconomy.\",\"verified\":0,\"followers_count\":175,\"friends_count\":397,\"favourites_count\":228,\"statuses_count\":410,\"listed_count\":12,\"name\":\"Daniel Adornes\",\"screen_name\":\"daniel_adornes\"}']\n",
    "test_data = [json.loads(t) for t in test_data]\n",
    "test_data = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ru</td>\n",
       "      <td>1</td>\n",
       "      <td>Светлана Петухова</td>\n",
       "      <td>svpetuhova26623</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>175</td>\n",
       "      <td>397</td>\n",
       "      <td>en</td>\n",
       "      <td>12</td>\n",
       "      <td>Daniel Adornes</td>\n",
       "      <td>daniel_adornes</td>\n",
       "      <td>410</td>\n",
       "      <td>Artist, Writer, Designer. Tweets on tech, cult...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228</td>\n",
       "      <td>175</td>\n",
       "      <td>397</td>\n",
       "      <td>en</td>\n",
       "      <td>12</td>\n",
       "      <td>Daniel Adornes</td>\n",
       "      <td>daniel_adornes</td>\n",
       "      <td>410</td>\n",
       "      <td>Artist, Writer, Designer. Tweets on tech, cult...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   favourites_count  followers_count  friends_count lang  listed_count  \\\n",
       "0                23                1              2   ru             1   \n",
       "1               228              175            397   en            12   \n",
       "2               228              175            397   en            12   \n",
       "\n",
       "                name      screen_name  statuses_count  \\\n",
       "0  Светлана Петухова  svpetuhova26623              14   \n",
       "1     Daniel Adornes   daniel_adornes             410   \n",
       "2     Daniel Adornes   daniel_adornes             410   \n",
       "\n",
       "                                             summary  verified  \n",
       "0                                                            0  \n",
       "1  Artist, Writer, Designer. Tweets on tech, cult...         0  \n",
       "2  Artist, Writer, Designer. Tweets on tech, cult...         0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = test_model.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business  person\n",
       "0       0.5     0.5\n",
       "1       0.3     0.7\n",
       "2       0.3     0.7"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result, columns=[\"business\",\"person\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
