{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Already trainned\n",
    "twitter_brands_lists1 = ['https://twitter.com/skysports/lists/sky-sports-brands',\n",
    "    'https://twitter.com/r4l/lists/sports-brands',\n",
    "    'https://twitter.com/totallyfuelled/lists/sports-brands',\n",
    "    'https://twitter.com/pipandnut/lists/fitness-brands',\n",
    "    'https://twitter.com/karenjashinsky/lists/fitness-brands',\n",
    "    'https://twitter.com/rebeccagoodyear/lists/health-brands',\n",
    "    'https://twitter.com/thiswomansword/lists/health-brands',\n",
    "    'https://twitter.com/carmax/lists/car-brands',\n",
    "    'https://twitter.com/carbuyingadvice/lists/car-brands',\n",
    "    'https://twitter.com/cbaccus/lists/automotive-brands',\n",
    "    'https://twitter.com/conversationage/lists/brands',\n",
    "    'https://twitter.com/mashable/lists/brands',\n",
    "    'https://twitter.com/scobleizer/lists/tech-news-brands',\n",
    "    'https://twitter.com/theoc/lists/brands',\n",
    "    'https://twitter.com/forbes/lists/best-business-schools',\n",
    "    'https://twitter.com/incycletv/lists/brands',\n",
    "    'https://twitter.com/bloombergtv/lists/luxury-brands',\n",
    "    'https://twitter.com/qbentm/lists/social-brands',\n",
    "    'https://twitter.com/mobiquitynet/lists/brands',\n",
    "    'https://twitter.com/chrisunwin/lists/brands',\n",
    "    'https://twitter.com/realtruckceo/lists/cool-brands',\n",
    "    'https://twitter.com/sboulton/lists/brands',\n",
    "    'https://twitter.com/robmcarpenter/lists/brands-i-like',\n",
    "    'https://twitter.com/iheartradio/lists/radio-stations',\n",
    "    'https://twitter.com/seeit/lists/tv-shows',\n",
    "    'https://twitter.com/secondsync/lists/tv-channels'\n",
    "]\n",
    "\n",
    "twitter_celebrities_lists = [\n",
    "    'https://twitter.com/nhl/lists/nhl-players',\n",
    "    'https://twitter.com/tddaily/lists/nfl-players',\n",
    "    'https://twitter.com/mlb/lists/players',\n",
    "    'https://twitter.com/azprepstar/lists/soccer-players',\n",
    "    'https://twitter.com/worldfootballor/lists/official-football-players',\n",
    "    'https://twitter.com/buzzedition/lists/the-celebrity-list',\n",
    "    'https://twitter.com/mashable/lists/celebrity',\n",
    "    'https://twitter.com/octagontheatre/lists/actors',\n",
    "    'https://twitter.com/patrickmwalshjr/lists/actors',\n",
    "    'https://twitter.com/jessieaskinazi/lists/actors',\n",
    "    'https://twitter.com/starpulse/lists/actors-actresses'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twitter import *\n",
    "\n",
    "token = '22911906-GR7LBJ2oil3cc27aUIAln4zur4F7CdKAKyEi6NDzi'\n",
    "token_key = 'FZbyPm1i3BMfiXKlKPuzBdRlvbenW09n8LX5OvgM85g'\n",
    "con_secret = 'cyZ6NLdySvTkhKGUGmXMKw'\n",
    "con_secret_key = '5UgOJOanohNPMVkfLY85CjzdMcNAAVBlRCyGYys'\n",
    "\n",
    "t = Twitter(auth=OAuth(token, token_key, con_secret, con_secret_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def tweets_from_lists(lists):\n",
    "    tweets = []\n",
    "    for twitter_list in lists:\n",
    "        slug = twitter_list.split('/')[-1]\n",
    "        owner = twitter_list.split('/')[-3]\n",
    "        max_id = None\n",
    "        for x in range(4):\n",
    "            try:\n",
    "                if max_id: \n",
    "                    statuses = t.lists.statuses(slug=slug, owner_screen_name=owner, count=200, max_id=max_id)\n",
    "                else:\n",
    "                    statuses = t.lists.statuses(slug=slug, owner_screen_name=owner, count=200)\n",
    "\n",
    "                if len(statuses) > 0: \n",
    "                    max_id = statuses[-1]['id']\n",
    "                    tweets += statuses\n",
    "\n",
    "                print('Downloaded', len(statuses), 'tweets from', '@' + owner, slug, 'list')\n",
    "            except:\n",
    "                print('Failed request for', '@' + owner, slug, 'list')\n",
    "        return tweets\n",
    "            \n",
    "def match_tweet_actor(tweet, tweet_list):\n",
    "    actor_tweet = tweet['user']['screen_name']\n",
    "    actor_tweet_list = list(map(lambda u: u['user']['screen_name'], tweet_list))\n",
    "    return actor_tweet not in actor_tweet_list\n",
    "\n",
    "def unique_tweets_list(original_list):\n",
    "    unique_list = []\n",
    "    for tweet in original_list:\n",
    "        if match_tweet_actor(tweet, unique_list): unique_list.append(tweet)\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 192 tweets from @skysports sky-sports-brands list\n",
      "Downloaded 188 tweets from @skysports sky-sports-brands list\n",
      "Downloaded 197 tweets from @skysports sky-sports-brands list\n",
      "Downloaded 74 tweets from @skysports sky-sports-brands list\n",
      "Downloaded 199 tweets from @r4l sports-brands list\n",
      "Downloaded 200 tweets from @r4l sports-brands list\n",
      "Downloaded 200 tweets from @r4l sports-brands list\n",
      "Downloaded 200 tweets from @r4l sports-brands list\n",
      "Downloaded 193 tweets from @totallyfuelled sports-brands list\n",
      "Downloaded 198 tweets from @totallyfuelled sports-brands list\n",
      "Downloaded 197 tweets from @totallyfuelled sports-brands list\n",
      "Downloaded 196 tweets from @totallyfuelled sports-brands list\n",
      "Downloaded 196 tweets from @pipandnut fitness-brands list\n",
      "Downloaded 199 tweets from @pipandnut fitness-brands list\n",
      "Downloaded 195 tweets from @pipandnut fitness-brands list\n",
      "Downloaded 200 tweets from @pipandnut fitness-brands list\n",
      "Downloaded 197 tweets from @karenjashinsky fitness-brands list\n",
      "Downloaded 194 tweets from @karenjashinsky fitness-brands list\n",
      "Downloaded 199 tweets from @karenjashinsky fitness-brands list\n",
      "Downloaded 193 tweets from @karenjashinsky fitness-brands list\n",
      "Downloaded 197 tweets from @rebeccagoodyear health-brands list\n",
      "Downloaded 200 tweets from @rebeccagoodyear health-brands list\n",
      "Downloaded 200 tweets from @rebeccagoodyear health-brands list\n",
      "Downloaded 200 tweets from @rebeccagoodyear health-brands list\n",
      "Downloaded 199 tweets from @thiswomansword health-brands list\n",
      "Downloaded 200 tweets from @thiswomansword health-brands list\n",
      "Downloaded 200 tweets from @thiswomansword health-brands list\n",
      "Downloaded 200 tweets from @thiswomansword health-brands list\n",
      "Downloaded 193 tweets from @carmax car-brands list\n",
      "Downloaded 200 tweets from @carmax car-brands list\n",
      "Downloaded 200 tweets from @carmax car-brands list\n",
      "Downloaded 200 tweets from @carmax car-brands list\n",
      "Downloaded 192 tweets from @carbuyingadvice car-brands list\n",
      "Downloaded 200 tweets from @carbuyingadvice car-brands list\n",
      "Downloaded 200 tweets from @carbuyingadvice car-brands list\n",
      "Downloaded 200 tweets from @carbuyingadvice car-brands list\n",
      "Downloaded 193 tweets from @cbaccus automotive-brands list\n",
      "Downloaded 191 tweets from @cbaccus automotive-brands list\n",
      "Downloaded 190 tweets from @cbaccus automotive-brands list\n",
      "Downloaded 190 tweets from @cbaccus automotive-brands list\n",
      "Downloaded 193 tweets from @conversationage brands list\n",
      "Downloaded 195 tweets from @conversationage brands list\n",
      "Downloaded 196 tweets from @conversationage brands list\n",
      "Downloaded 193 tweets from @conversationage brands list\n",
      "Downloaded 196 tweets from @mashable brands list\n",
      "Downloaded 195 tweets from @mashable brands list\n",
      "Downloaded 194 tweets from @mashable brands list\n",
      "Downloaded 183 tweets from @mashable brands list\n",
      "Downloaded 200 tweets from @scobleizer tech-news-brands list\n",
      "Downloaded 199 tweets from @scobleizer tech-news-brands list\n",
      "Downloaded 198 tweets from @scobleizer tech-news-brands list\n",
      "Downloaded 199 tweets from @scobleizer tech-news-brands list\n",
      "Downloaded 196 tweets from @theoc brands list\n",
      "Downloaded 189 tweets from @theoc brands list\n",
      "Downloaded 198 tweets from @theoc brands list\n",
      "Downloaded 199 tweets from @theoc brands list\n",
      "Downloaded 194 tweets from @forbes best-business-schools list\n",
      "Downloaded 197 tweets from @forbes best-business-schools list\n",
      "Downloaded 192 tweets from @forbes best-business-schools list\n",
      "Downloaded 193 tweets from @forbes best-business-schools list\n",
      "Downloaded 194 tweets from @incycletv brands list\n",
      "Downloaded 188 tweets from @incycletv brands list\n",
      "Downloaded 195 tweets from @incycletv brands list\n",
      "Downloaded 197 tweets from @incycletv brands list\n",
      "Downloaded 192 tweets from @bloombergtv luxury-brands list\n",
      "Downloaded 195 tweets from @bloombergtv luxury-brands list\n",
      "Failed request for @bloombergtv luxury-brands list\n",
      "Downloaded 194 tweets from @bloombergtv luxury-brands list\n",
      "Downloaded 198 tweets from @qbentm social-brands list\n",
      "Downloaded 195 tweets from @qbentm social-brands list\n",
      "Downloaded 198 tweets from @qbentm social-brands list\n",
      "Downloaded 200 tweets from @qbentm social-brands list\n",
      "Downloaded 188 tweets from @mobiquitynet brands list\n",
      "Downloaded 191 tweets from @mobiquitynet brands list\n",
      "Downloaded 193 tweets from @mobiquitynet brands list\n",
      "Downloaded 191 tweets from @mobiquitynet brands list\n",
      "Downloaded 196 tweets from @chrisunwin brands list\n",
      "Downloaded 198 tweets from @chrisunwin brands list\n",
      "Downloaded 196 tweets from @chrisunwin brands list\n",
      "Downloaded 195 tweets from @chrisunwin brands list\n",
      "Downloaded 198 tweets from @realtruckceo cool-brands list\n",
      "Downloaded 200 tweets from @realtruckceo cool-brands list\n",
      "Failed request for @realtruckceo cool-brands list\n",
      "Downloaded 199 tweets from @realtruckceo cool-brands list\n",
      "Downloaded 199 tweets from @sboulton brands list\n",
      "Downloaded 197 tweets from @sboulton brands list\n",
      "Downloaded 198 tweets from @sboulton brands list\n",
      "Failed request for @sboulton brands list\n",
      "Downloaded 197 tweets from @robmcarpenter brands-i-like list\n",
      "Downloaded 199 tweets from @robmcarpenter brands-i-like list\n",
      "Downloaded 199 tweets from @robmcarpenter brands-i-like list\n",
      "Downloaded 199 tweets from @robmcarpenter brands-i-like list\n",
      "Downloaded 199 tweets from @iheartradio radio-stations list\n",
      "Downloaded 199 tweets from @iheartradio radio-stations list\n",
      "Downloaded 199 tweets from @iheartradio radio-stations list\n",
      "Downloaded 198 tweets from @iheartradio radio-stations list\n",
      "Downloaded 197 tweets from @seeit tv-shows list\n",
      "Downloaded 190 tweets from @seeit tv-shows list\n",
      "Downloaded 192 tweets from @seeit tv-shows list\n",
      "Downloaded 197 tweets from @seeit tv-shows list\n",
      "Downloaded 199 tweets from @secondsync tv-channels list\n",
      "Downloaded 198 tweets from @secondsync tv-channels list\n",
      "Downloaded 199 tweets from @secondsync tv-channels list\n",
      "Downloaded 200 tweets from @secondsync tv-channels list\n",
      "Downloaded 191 tweets from @nhl nhl-players list\n",
      "Downloaded 193 tweets from @nhl nhl-players list\n",
      "Downloaded 189 tweets from @nhl nhl-players list\n",
      "Downloaded 178 tweets from @nhl nhl-players list\n",
      "Downloaded 195 tweets from @tddaily nfl-players list\n",
      "Downloaded 196 tweets from @tddaily nfl-players list\n",
      "Downloaded 194 tweets from @tddaily nfl-players list\n",
      "Downloaded 195 tweets from @tddaily nfl-players list\n",
      "Downloaded 198 tweets from @mlb players list\n",
      "Downloaded 193 tweets from @mlb players list\n",
      "Downloaded 194 tweets from @mlb players list\n",
      "Downloaded 170 tweets from @mlb players list\n",
      "Downloaded 165 tweets from @azprepstar soccer-players list\n",
      "Downloaded 187 tweets from @azprepstar soccer-players list\n",
      "Downloaded 173 tweets from @azprepstar soccer-players list\n",
      "Downloaded 170 tweets from @azprepstar soccer-players list\n",
      "Downloaded 194 tweets from @worldfootballor official-football-players list\n",
      "Downloaded 194 tweets from @worldfootballor official-football-players list\n",
      "Downloaded 195 tweets from @worldfootballor official-football-players list\n",
      "Downloaded 191 tweets from @worldfootballor official-football-players list\n",
      "Downloaded 194 tweets from @buzzedition the-celebrity-list list\n",
      "Downloaded 197 tweets from @buzzedition the-celebrity-list list\n",
      "Downloaded 186 tweets from @buzzedition the-celebrity-list list\n",
      "Downloaded 194 tweets from @buzzedition the-celebrity-list list\n",
      "Downloaded 192 tweets from @mashable celebrity list\n",
      "Downloaded 160 tweets from @mashable celebrity list\n",
      "Downloaded 183 tweets from @mashable celebrity list\n",
      "Downloaded 184 tweets from @mashable celebrity list\n",
      "Downloaded 193 tweets from @octagontheatre actors list\n",
      "Downloaded 194 tweets from @octagontheatre actors list\n",
      "Downloaded 194 tweets from @octagontheatre actors list\n",
      "Failed request for @octagontheatre actors list\n",
      "Failed request for @patrickmwalshjr actors list\n",
      "Failed request for @patrickmwalshjr actors list\n",
      "Failed request for @patrickmwalshjr actors list\n",
      "Failed request for @patrickmwalshjr actors list\n",
      "Failed request for @jessieaskinazi actors list\n",
      "Failed request for @jessieaskinazi actors list\n",
      "Failed request for @jessieaskinazi actors list\n",
      "Failed request for @jessieaskinazi actors list\n",
      "Failed request for @starpulse actors-actresses list\n",
      "Failed request for @starpulse actors-actresses list\n",
      "Failed request for @starpulse actors-actresses list\n",
      "Failed request for @starpulse actors-actresses list\n"
     ]
    }
   ],
   "source": [
    "# Download data.. takes a long time to run\n",
    "brand_tweets = []\n",
    "for _list in twitter_brands_lists:\n",
    "    brand_tweets += tweets_from_lists([_list]) \n",
    "\n",
    "person_tweets = []\n",
    "for _list in twitter_celebrities_lists:\n",
    "    person_tweets += tweets_from_lists([_list]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19697\n",
      "\n",
      "##########\n",
      "###\n",
      "###\n",
      "brand_unique_tweets: 1449\n",
      "person_unique_tweets: 1181\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_tweets))\n",
    "brand_unique_tweets = unique_tweets_list(brand_tweets)\n",
    "person_unique_tweets = unique_tweets_list(person_tweets)\n",
    "\n",
    "print('')\n",
    "print('##########')\n",
    "print('###')\n",
    "print('###')\n",
    "print('brand_unique_tweets:', len(brand_unique_tweets))\n",
    "print('person_unique_tweets:', len(person_unique_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import csv\n",
    "from html import escape\n",
    "\n",
    "def persist_complete_data(file_name, data):\n",
    "    \n",
    "    s = 0\n",
    "    with open(file_name, 'w') as csv_file:\n",
    "        tweets_writer = csv.writer(csv_file)\n",
    "        tweets_writer.writerow([\n",
    "            'actor_id',\n",
    "            'actor_screen_name',\n",
    "            'actor_name',\n",
    "            'actor_verified',\n",
    "            'actor_friends_count',\n",
    "            'actor_followers_count',\n",
    "            'actor_listed_count',\n",
    "            'actor_statuses_count',\n",
    "            'actor_favorites_count',\n",
    "            'actor_summary',\n",
    "            'actor_created_at',\n",
    "            'actor_location',\n",
    "\n",
    "            'tweet_id',\n",
    "            'tweet_created_at',\n",
    "            'tweet_generator',\n",
    "            'tweet_body',\n",
    "            'tweet_verb',\n",
    "\n",
    "            'tweet_urls_count',\n",
    "            'tweet_mentions_count',\n",
    "            'tweet_hashtags_count',\n",
    "            'tweet_trends_count',\n",
    "            'tweet_symbols_count'])\n",
    "        for tweet in data:\n",
    "            tweets_writer.writerow([\n",
    "                tweet['user']['id'],\n",
    "                tweet['user']['screen_name'],\n",
    "                tweet['user']['name'],\n",
    "                tweet['user']['verified'],\n",
    "                tweet['user']['friends_count'],\n",
    "                tweet['user']['followers_count'],\n",
    "                tweet['user']['listed_count'],\n",
    "                tweet['user']['statuses_count'],\n",
    "                tweet['user']['favourites_count'],\n",
    "                tweet['user']['description'],\n",
    "                tweet['user']['created_at'],\n",
    "                tweet['user']['location'] if tweet['user'].get('location') else 'null',\n",
    "\n",
    "                tweet['id'],\n",
    "                tweet['created_at'],\n",
    "                re.findall('>(.*)<', tweet['source'])[0],\n",
    "                tweet['text'],\n",
    "                not tweet['retweeted'],\n",
    "                len(tweet['entities']['urls']),\n",
    "                len(tweet['entities']['user_mentions']),\n",
    "                len(tweet['entities']['hashtags']),\n",
    "                \"\",\n",
    "                len(tweet['entities']['symbols'])\n",
    "            ])\n",
    "            s += 1\n",
    "            if (s % 100 == 0): print('Already writed', s, 'rows to', file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already writed 100 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 200 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 300 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 400 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 500 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 600 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 700 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 800 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 900 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 1000 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 1100 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 1200 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 1300 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 1400 rows to data/csv/brand_lists_scraped_trained.csv\n",
      "Already writed 100 rows to data/csv/person_lists_scraped_trained.csv\n",
      "Already writed 200 rows to data/csv/person_lists_scraped_trained.csv\n",
      "Already writed 300 rows to data/csv/person_lists_scraped_trained.csv\n",
      "Already writed 400 rows to data/csv/person_lists_scraped_trained.csv\n",
      "Already writed 500 rows to data/csv/person_lists_scraped_trained.csv\n",
      "Already writed 600 rows to data/csv/person_lists_scraped_trained.csv\n",
      "Already writed 700 rows to data/csv/person_lists_scraped_trained.csv\n",
      "Already writed 800 rows to data/csv/person_lists_scraped_trained.csv\n",
      "Already writed 900 rows to data/csv/person_lists_scraped_trained.csv\n",
      "Already writed 1000 rows to data/csv/person_lists_scraped_trained.csv\n",
      "Already writed 1100 rows to data/csv/person_lists_scraped_trained.csv\n"
     ]
    }
   ],
   "source": [
    "persist_complete_data('../data/csv/brand_lists_scraped_trained.csv', brand_unique_tweets)\n",
    "persist_complete_data('../data/csv/person_lists_scraped_trained.csv', person_unique_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
